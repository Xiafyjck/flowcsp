{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 晶体结构生成推理 Notebook - 迭代优化版\n",
    "\n",
    "本notebook实现迭代优化的推理流程：\n",
    "\n",
    "## 核心流程\n",
    "1. **初始推理**：模型推理生成初始submission.csv\n",
    "2. **质量评估**：使用RWP指标评估PXRD匹配质量\n",
    "3. **迭代优化循环**：\n",
    "   - 质量不好的样本进行后处理（能量优化→Rietveld精修）\n",
    "   - 如果质量改善则更新submission.csv\n",
    "   - 仍不满足要求的批量重新生成\n",
    "4. **终止条件**：\n",
    "   - 总运行时间超过5小时\n",
    "   - 单个样本尝试次数超限\n",
    "   - 所有样本满足质量要求\n",
    "\n",
    "**注意**: 这个notebook设计为可直接在比赛环境运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库和设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\nimport sys\nimport time\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom tqdm.auto import tqdm\nfrom pymatgen.core import Structure, Lattice, Composition, Element\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# 添加src目录到路径\nsys.path.append('.')  # 添加根目录\nsys.path.append('src')\n\n# 导入必要的模块\nfrom src.trainer import CrystalGenerationModule\nfrom src.pxrd_simulator import PXRDSimulator\nfrom src.normalizer import LatticeNormalizer\n\n# 设置随机种子\nnp.random.seed(42)\ntorch.manual_seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(42)\n\nprint(f\"PyTorch版本: {torch.__version__}\")\nprint(f\"CUDA可用: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA设备: {torch.cuda.get_device_name(0)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 数据路径配置\nDATA_DIR = Path(\"data/A_sample\")  # 比赛数据目录\nCOMPOSITION_FILE = DATA_DIR / \"composition.json\"\nPATTERN_DIR = DATA_DIR / \"pattern\"\n\n# 模型路径 - 使用实际的checkpoint路径\nMODEL_PATH = \"outputs/transformer_cfm_20250828_144134/checkpoints/last.ckpt\"\n\n# 输出文件（必须在根目录）\nSUBMISSION_FILE = \"submission.csv\"\n\n# 优化参数\nRWP_THRESHOLD = 0.15  # RWP质量阈值，低于此值认为质量合格\nMAX_TIME_HOURS = 5  # 最大运行时间（小时）\nMAX_ATTEMPTS_PER_SAMPLE = 10  # 每个样本最大尝试次数\nBATCH_SIZE = 32  # 批量重新生成的大小\n\n# 记录开始时间\nSTART_TIME = time.time()\nMAX_RUNTIME = MAX_TIME_HOURS * 3600  # 转换为秒\n\nprint(f\"配置参数：\")\nprint(f\"  模型路径: {MODEL_PATH}\")\nprint(f\"  模型存在: {os.path.exists(MODEL_PATH)}\")\nprint(f\"  RWP阈值: {RWP_THRESHOLD}\")\nprint(f\"  最大运行时间: {MAX_TIME_HOURS}小时\")\nprint(f\"  单样本最大尝试: {MAX_ATTEMPTS_PER_SAMPLE}次\")\nprint(f\"  开始时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据加载函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xy_file(file_path):\n",
    "    \"\"\"读取.xy格式的PXRD数据\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                intensity = float(parts[1])\n",
    "                data.append(intensity)\n",
    "    return np.array(data, dtype=np.float32)\n",
    "\n",
    "def parse_composition(comp_str):\n",
    "    \"\"\"解析组成字符串为原子类型和数量\"\"\"\n",
    "    comp = Composition(comp_str)\n",
    "    atom_list = []\n",
    "    \n",
    "    for element, count in comp.items():\n",
    "        atomic_num = Element(element).Z\n",
    "        atom_list.extend([atomic_num] * int(count))\n",
    "    \n",
    "    # 填充到60维\n",
    "    atom_types = np.zeros(60, dtype=np.int32)\n",
    "    atom_types[:len(atom_list)] = atom_list[:60]\n",
    "    \n",
    "    return len(atom_list), atom_types\n",
    "\n",
    "def load_competition_data(data_dir):\n",
    "    \"\"\"加载比赛格式数据\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # 读取composition\n",
    "    with open(data_dir / \"composition.json\", 'r') as f:\n",
    "        compositions = json.load(f)\n",
    "    \n",
    "    # 准备数据列表\n",
    "    data_list = []\n",
    "    \n",
    "    for sample_id, comp_info in tqdm(compositions.items(), desc=\"加载数据\"):\n",
    "        # 获取组成信息\n",
    "        comp_list = comp_info[\"composition\"]\n",
    "        niggli_comp = comp_list[0]\n",
    "        primitive_comp = comp_list[1] if len(comp_list) > 1 else comp_list[0]\n",
    "        \n",
    "        # 解析原子信息\n",
    "        num_atoms, atom_types = parse_composition(niggli_comp)\n",
    "        \n",
    "        # 读取PXRD数据\n",
    "        pattern_file = data_dir / \"pattern\" / f\"{sample_id}.xy\"\n",
    "        if pattern_file.exists():\n",
    "            pxrd = read_xy_file(pattern_file)\n",
    "            # 确保长度为11501\n",
    "            if len(pxrd) < 11501:\n",
    "                pxrd_full = np.zeros(11501, dtype=np.float32)\n",
    "                pxrd_full[:len(pxrd)] = pxrd\n",
    "                pxrd = pxrd_full\n",
    "            elif len(pxrd) > 11501:\n",
    "                pxrd = pxrd[:11501]\n",
    "        else:\n",
    "            pxrd = np.zeros(11501, dtype=np.float32)\n",
    "        \n",
    "        data_list.append({\n",
    "            'id': sample_id,\n",
    "            'niggli_comp': niggli_comp,\n",
    "            'primitive_comp': primitive_comp,\n",
    "            'atom_types': atom_types,\n",
    "            'num_atoms': num_atoms,\n",
    "            'pxrd': pxrd  # 观测的PXRD谱\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载比赛数据\n",
    "df = load_competition_data(DATA_DIR)\n",
    "print(f\"\\n加载了 {len(df)} 个样本\")\n",
    "print(f\"数据列: {df.columns.tolist()}\")\n",
    "print(f\"\\n前5个样本:\")\n",
    "print(df[['id', 'niggli_comp', 'num_atoms']].head())\n",
    "\n",
    "# 初始化样本状态追踪\n",
    "sample_status = {\n",
    "    sample_id: {\n",
    "        'attempts': 0,\n",
    "        'best_rwp': float('inf'),\n",
    "        'best_structure': None,\n",
    "        'satisfied': False\n",
    "    }\n",
    "    for sample_id in df['id']\n",
    "}\n",
    "\n",
    "print(f\"\\n初始化了 {len(sample_status)} 个样本的状态追踪\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型和推理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 加载模型和初始化工具\ndef load_model(model_path):\n    \"\"\"\n    加载训练好的模型\n    \n    Args:\n        model_path: checkpoint文件路径\n        \n    Returns:\n        加载好的Lightning模块\n    \"\"\"\n    print(f\"正在加载模型: {model_path}\")\n    \n    # 从checkpoint加载模型\n    model = CrystalGenerationModule.load_from_checkpoint(\n        model_path,\n        map_location='cuda' if torch.cuda.is_available() else 'cpu'\n    )\n    \n    # 设置为评估模式\n    model.eval()\n    \n    # 移动到正确的设备\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    \n    print(f\"模型加载成功，设备: {device}\")\n    return model\n\ndef prepare_batch_for_model(sample_df, device):\n    \"\"\"\n    准备模型输入批次\n    \n    Args:\n        sample_df: 包含样本数据的DataFrame\n        device: 计算设备\n        \n    Returns:\n        dict: 模型输入批次\n    \"\"\"\n    batch = {\n        'comp': torch.tensor(np.stack(sample_df['atom_types'].values), dtype=torch.float32).to(device),\n        'pxrd': torch.tensor(np.stack(sample_df['pxrd'].values), dtype=torch.float32).to(device),\n        'num_atoms': torch.tensor(sample_df['num_atoms'].values, dtype=torch.long).to(device),\n    }\n    return batch\n\ndef generate_crystal_structure(sample, model, lattice_normalizer, pxrd_simulator):\n    \"\"\"\n    使用模型生成晶体结构\n    \n    Args:\n        sample: 包含pxrd、atom_types、num_atoms等信息的样本\n        model: 训练好的模型\n        lattice_normalizer: 晶格归一化器\n        pxrd_simulator: PXRD仿真器\n    \n    Returns:\n        Structure对象\n    \"\"\"\n    device = next(model.parameters()).device\n    \n    # 准备单个样本的批次\n    batch = {\n        'comp': torch.tensor(sample['atom_types'], dtype=torch.float32).unsqueeze(0).to(device),\n        'pxrd': torch.tensor(sample['pxrd'], dtype=torch.float32).unsqueeze(0).to(device),\n        'num_atoms': torch.tensor([sample['num_atoms']], dtype=torch.long).to(device),\n    }\n    \n    # 模型推理\n    with torch.no_grad():\n        # 使用flow的sample方法生成\n        generated = model.flow.sample(batch)  # [1, 63, 3]\n        \n    # 转换到CPU并提取数据\n    generated = generated.cpu().numpy()[0]  # [63, 3]\n    \n    # 分离晶格和分数坐标\n    lattice_vectors = generated[:3, :]  # [3, 3] 归一化的晶格向量\n    frac_coords = generated[3:3+sample['num_atoms'], :]  # [num_atoms, 3]\n    \n    # 反归一化晶格参数\n    lattice_matrix = lattice_normalizer.denormalize_lattice(\n        torch.tensor(lattice_vectors, dtype=torch.float32).unsqueeze(0)\n    ).numpy()[0]\n    \n    # 确保分数坐标在[0,1]范围内\n    frac_coords = np.mod(frac_coords, 1.0)\n    \n    # 获取元素列表\n    species = []\n    for i in range(sample['num_atoms']):\n        atomic_num = int(sample['atom_types'][i])\n        if atomic_num > 0:\n            species.append(Element.from_Z(atomic_num))\n    \n    # 创建Structure对象\n    try:\n        lattice = Lattice(lattice_matrix)\n        structure = Structure(\n            lattice=lattice,\n            species=species,\n            coords=frac_coords,\n            coords_are_cartesian=False\n        )\n    except Exception as e:\n        print(f\"创建Structure失败: {e}\")\n        # 回退到随机生成\n        return generate_random_structure(sample)\n    \n    return structure\n\ndef generate_random_structure(sample):\n    \"\"\"\n    生成随机晶体结构（备用方案）\n    \n    Args:\n        sample: 样本数据\n        \n    Returns:\n        Structure对象\n    \"\"\"\n    num_atoms = sample['num_atoms']\n    \n    # 随机晶格参数\n    a = np.random.uniform(3, 10)\n    b = np.random.uniform(3, 10)\n    c = np.random.uniform(3, 10)\n    alpha = np.random.uniform(60, 120)\n    beta = np.random.uniform(60, 120)\n    gamma = np.random.uniform(60, 120)\n    \n    lattice = Lattice.from_parameters(a, b, c, alpha, beta, gamma)\n    frac_coords = np.random.rand(num_atoms, 3)\n    \n    species = []\n    for i in range(num_atoms):\n        atomic_num = int(sample['atom_types'][i])\n        if atomic_num > 0:\n            species.append(Element.from_Z(atomic_num))\n    \n    return Structure(\n        lattice=lattice,\n        species=species,\n        coords=frac_coords,\n        coords_are_cartesian=False\n    )\n\n# 加载模型和初始化工具\ntry:\n    model = load_model(MODEL_PATH)\n    lattice_normalizer = LatticeNormalizer()\n    pxrd_simulator = PXRDSimulator()\n    print(\"✅ 模型和工具初始化成功\")\nexcept Exception as e:\n    print(f\"⚠️ 模型加载失败: {e}\")\n    print(\"将使用随机生成作为备用方案\")\n    model = None\n    lattice_normalizer = None\n    pxrd_simulator = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PXRD计算和质量评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def calculate_pxrd(structure, pxrd_simulator=None):\n    \"\"\"\n    计算晶体结构的PXRD谱\n    \n    Args:\n        structure: pymatgen Structure对象\n        pxrd_simulator: PXRD仿真器实例\n    \n    Returns:\n        np.array: 11501维的PXRD强度数组\n    \"\"\"\n    if pxrd_simulator is None:\n        # 如果没有提供simulator，创建一个新的\n        from src.PXRDSimulator import PXRDSimulator\n        pxrd_simulator = PXRDSimulator()\n    \n    try:\n        # 使用PXRDSimulator计算PXRD\n        pxrd_calc = pxrd_simulator.get_pattern(structure)\n        \n        # 确保返回11501维\n        if len(pxrd_calc) < 11501:\n            pxrd_full = np.zeros(11501, dtype=np.float32)\n            pxrd_full[:len(pxrd_calc)] = pxrd_calc\n            pxrd_calc = pxrd_full\n        elif len(pxrd_calc) > 11501:\n            pxrd_calc = pxrd_calc[:11501]\n            \n        return pxrd_calc\n        \n    except Exception as e:\n        print(f\"PXRD计算失败: {e}\")\n        # 返回随机PXRD作为备用\n        pxrd_calc = np.random.rand(11501) * 100\n        pxrd_calc[pxrd_calc < 10] = 0\n        return pxrd_calc\n\ndef evaluate_structure_quality(structure, observed_pxrd, pxrd_simulator=None):\n    \"\"\"\n    评估生成结构的质量\n    \n    Args:\n        structure: 生成的Structure对象\n        observed_pxrd: 观测的PXRD谱\n        pxrd_simulator: PXRD仿真器实例\n    \n    Returns:\n        float: RWP值（越小越好）\n    \"\"\"\n    # 计算生成结构的PXRD\n    calculated_pxrd = calculate_pxrd(structure, pxrd_simulator)\n    \n    # 简单的RWP计算（如果没有专门的metrics模块）\n    try:\n        from src.metrics import rwp\n        rwp_value = rwp(calculated_pxrd, observed_pxrd)\n    except ImportError:\n        # 备用RWP计算\n        diff = calculated_pxrd - observed_pxrd\n        weighted_diff = diff * np.sqrt(np.maximum(observed_pxrd, 1e-10))\n        rwp_value = np.sqrt(np.sum(weighted_diff**2) / np.sum(observed_pxrd**2 + 1e-10))\n    \n    return rwp_value"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 后处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_optimization(structure):\n",
    "    \"\"\"\n",
    "    能量优化\n",
    "    \n",
    "    Args:\n",
    "        structure: 待优化的Structure对象\n",
    "    \n",
    "    Returns:\n",
    "        Structure: 优化后的结构\n",
    "    \"\"\"\n",
    "    # TODO: 实现能量优化\n",
    "    # 可以使用GULP、VASP、或机器学习势函数等\n",
    "    \n",
    "    # 占位：稍微调整晶格参数模拟优化\n",
    "    new_lattice = structure.lattice.matrix * np.random.uniform(0.98, 1.02)\n",
    "    optimized = Structure(\n",
    "        lattice=Lattice(new_lattice),\n",
    "        species=structure.species,\n",
    "        coords=structure.frac_coords,\n",
    "        coords_are_cartesian=False\n",
    "    )\n",
    "    \n",
    "    return optimized\n",
    "\n",
    "def rietveld_refinement(structure, observed_pxrd):\n",
    "    \"\"\"\n",
    "    Rietveld精修\n",
    "    \n",
    "    Args:\n",
    "        structure: 待精修的Structure对象\n",
    "        observed_pxrd: 观测的PXRD谱\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (精修后的Structure, 是否需要精修)\n",
    "    \"\"\"\n",
    "    # 判断是否需要精修\n",
    "    current_rwp = evaluate_structure_quality(structure, observed_pxrd)\n",
    "    needs_refinement = current_rwp > RWP_THRESHOLD * 1.5  # 如果RWP较高则需要精修\n",
    "    \n",
    "    if not needs_refinement:\n",
    "        return structure, False\n",
    "    \n",
    "    # TODO: 实现Rietveld精修\n",
    "    # 可以使用GSAS-II、TOPAS、FullProf等\n",
    "    \n",
    "    # 占位：稍微调整原子位置模拟精修\n",
    "    new_coords = structure.frac_coords + np.random.randn(*structure.frac_coords.shape) * 0.01\n",
    "    new_coords = np.clip(new_coords, 0, 1)  # 确保在[0,1]范围内\n",
    "    \n",
    "    refined = Structure(\n",
    "        lattice=structure.lattice,\n",
    "        species=structure.species,\n",
    "        coords=new_coords,\n",
    "        coords_are_cartesian=False\n",
    "    )\n",
    "    \n",
    "    return refined, True\n",
    "\n",
    "def post_process_structure(structure, observed_pxrd):\n",
    "    \"\"\"\n",
    "    完整的后处理流程\n",
    "    \n",
    "    Args:\n",
    "        structure: 待处理的Structure对象\n",
    "        observed_pxrd: 观测的PXRD谱\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (处理后的Structure, 最终RWP值)\n",
    "    \"\"\"\n",
    "    # 1. 能量优化\n",
    "    optimized = energy_optimization(structure)\n",
    "    rwp_after_opt = evaluate_structure_quality(optimized, observed_pxrd)\n",
    "    \n",
    "    # 2. Rietveld精修（如果需要）\n",
    "    refined, was_refined = rietveld_refinement(optimized, observed_pxrd)\n",
    "    \n",
    "    if was_refined:\n",
    "        rwp_after_refine = evaluate_structure_quality(refined, observed_pxrd)\n",
    "        return refined, rwp_after_refine\n",
    "    else:\n",
    "        return optimized, rwp_after_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 终止条件检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_termination_conditions(sample_status):\n",
    "    \"\"\"\n",
    "    检查是否满足终止条件\n",
    "    \n",
    "    终止条件：\n",
    "    1. 运行时间超过5小时\n",
    "    2. 所有样本都满足质量要求或达到最大尝试次数\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (是否终止, 终止原因)\n",
    "    \"\"\"\n",
    "    # 检查运行时间\n",
    "    elapsed_time = time.time() - START_TIME\n",
    "    if elapsed_time > MAX_RUNTIME:\n",
    "        return True, f\"达到最大运行时间 {MAX_TIME_HOURS} 小时\"\n",
    "    \n",
    "    # 检查所有样本状态\n",
    "    all_done = all(\n",
    "        status['satisfied'] or status['attempts'] >= MAX_ATTEMPTS_PER_SAMPLE\n",
    "        for status in sample_status.values()\n",
    "    )\n",
    "    \n",
    "    if all_done:\n",
    "        satisfied_count = sum(1 for s in sample_status.values() if s['satisfied'])\n",
    "        return True, f\"所有样本处理完成（{satisfied_count}/{len(sample_status)}满足要求）\"\n",
    "    \n",
    "    return False, None\n",
    "\n",
    "def get_samples_to_regenerate(sample_status, batch_size=32):\n",
    "    \"\"\"\n",
    "    获取需要重新生成的样本\n",
    "    \n",
    "    Args:\n",
    "        sample_status: 样本状态字典\n",
    "        batch_size: 批次大小\n",
    "    \n",
    "    Returns:\n",
    "        list: 需要重新生成的样本ID列表\n",
    "    \"\"\"\n",
    "    # 找出未满足要求且未超过尝试次数的样本\n",
    "    candidates = [\n",
    "        sample_id for sample_id, status in sample_status.items()\n",
    "        if not status['satisfied'] and status['attempts'] < MAX_ATTEMPTS_PER_SAMPLE\n",
    "    ]\n",
    "    \n",
    "    # 按RWP值排序，优先处理质量最差的\n",
    "    candidates.sort(key=lambda x: sample_status[x]['best_rwp'], reverse=True)\n",
    "    \n",
    "    return candidates[:batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12. 初始推理（带实时保存）"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*60)\nprint(\"阶段1：初始推理\")\nprint(\"=\"*60)\n\ninitial_predictions = {}\n\nfor idx, row in tqdm(df.iterrows(), total=len(df), desc=\"初始推理\"):\n    sample_id = row['id']\n    \n    # 生成初始结构\n    if model is not None:\n        structure = generate_crystal_structure(row, model, lattice_normalizer, pxrd_simulator)\n    else:\n        structure = generate_random_structure(row)\n    \n    # 评估质量\n    rwp_value = evaluate_structure_quality(structure, row['pxrd'], pxrd_simulator)\n    \n    # 更新状态\n    sample_status[sample_id]['attempts'] = 1\n    sample_status[sample_id]['best_rwp'] = rwp_value\n    sample_status[sample_id]['best_structure'] = structure\n    sample_status[sample_id]['satisfied'] = rwp_value < RWP_THRESHOLD\n    \n    initial_predictions[sample_id] = structure\n\n# 统计初始结果\nsatisfied_count = sum(1 for s in sample_status.values() if s['satisfied'])\navg_rwp = np.mean([s['best_rwp'] for s in sample_status.values()])\n\nprint(f\"\\n初始推理结果:\")\nprint(f\"  满足要求: {satisfied_count}/{len(sample_status)} ({satisfied_count/len(sample_status)*100:.1f}%)\")\nprint(f\"  平均RWP: {avg_rwp:.4f}\")\nprint(f\"  RWP阈值: {RWP_THRESHOLD}\")\n\n# 立即保存初始推理结果到submission.csv\nsubmission_df = update_submission_incrementally(sample_status, DATA_DIR, SUBMISSION_FILE)\nlog_submission_update(0, sample_status, SUBMISSION_FILE)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 13. 迭代优化循环（带实时保存）"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*60)\nprint(\"阶段2：迭代优化\")\nprint(\"=\"*60)\n\niteration = 0\nwhile True:\n    iteration += 1\n    \n    # 检查终止条件\n    should_terminate, reason = check_termination_conditions(sample_status)\n    if should_terminate:\n        print(f\"\\n终止优化: {reason}\")\n        break\n    \n    print(f\"\\n--- 迭代 {iteration} ---\")\n    elapsed = time.time() - START_TIME\n    print(f\"已运行: {elapsed/3600:.2f}小时\")\n    \n    # 获取需要优化的样本\n    samples_to_process = get_samples_to_regenerate(sample_status, BATCH_SIZE)\n    \n    if not samples_to_process:\n        print(\"没有需要处理的样本\")\n        break\n    \n    print(f\"处理 {len(samples_to_process)} 个样本\")\n    \n    # 标记是否有改进\n    has_improvement = False\n    \n    # 处理每个样本\n    for sample_id in tqdm(samples_to_process, desc=f\"迭代{iteration}\"):\n        row = df[df['id'] == sample_id].iloc[0]\n        current_best = sample_status[sample_id]['best_structure']\n        current_rwp = sample_status[sample_id]['best_rwp']\n        initial_rwp = current_rwp  # 记录改进前的RWP\n        \n        # 策略1：后处理当前最佳结构\n        if sample_status[sample_id]['attempts'] < MAX_ATTEMPTS_PER_SAMPLE // 2:\n            processed_structure, processed_rwp = post_process_structure(\n                current_best, row['pxrd']\n            )\n            \n            if processed_rwp < current_rwp:\n                sample_status[sample_id]['best_structure'] = processed_structure\n                sample_status[sample_id]['best_rwp'] = processed_rwp\n                sample_status[sample_id]['satisfied'] = processed_rwp < RWP_THRESHOLD\n                current_rwp = processed_rwp\n                has_improvement = True\n        \n        # 策略2：如果质量仍不满足，重新生成\n        if not sample_status[sample_id]['satisfied']:\n            if model is not None:\n                new_structure = generate_crystal_structure(row, model, lattice_normalizer, pxrd_simulator)\n            else:\n                new_structure = generate_random_structure(row)\n                \n            new_rwp = evaluate_structure_quality(new_structure, row['pxrd'], pxrd_simulator)\n            \n            # 后处理新生成的结构\n            processed_new, processed_new_rwp = post_process_structure(\n                new_structure, row['pxrd']\n            )\n            \n            # 保留最佳结果\n            if processed_new_rwp < sample_status[sample_id]['best_rwp']:\n                sample_status[sample_id]['best_structure'] = processed_new\n                sample_status[sample_id]['best_rwp'] = processed_new_rwp\n                sample_status[sample_id]['satisfied'] = processed_new_rwp < RWP_THRESHOLD\n                has_improvement = True\n        \n        # 更新尝试次数\n        sample_status[sample_id]['attempts'] += 1\n    \n    # 统计当前状态\n    satisfied_count = sum(1 for s in sample_status.values() if s['satisfied'])\n    avg_rwp = np.mean([s['best_rwp'] for s in sample_status.values()])\n    \n    print(f\"\\n迭代{iteration}结果:\")\n    print(f\"  满足要求: {satisfied_count}/{len(sample_status)} ({satisfied_count/len(sample_status)*100:.1f}%)\")\n    print(f\"  平均RWP: {avg_rwp:.4f}\")\n    \n    # 每次迭代后都更新submission.csv（无论是否有改进）\n    submission_df = update_submission_incrementally(sample_status, DATA_DIR, SUBMISSION_FILE)\n    log_submission_update(iteration, sample_status, SUBMISSION_FILE)\n    \n    # 如果有改进，输出改进信息\n    if has_improvement:\n        print(\"  ✨ 本轮有样本得到改进\")\n    \n    # 限制迭代次数（额外保护）\n    if iteration > 100:\n        print(\"达到最大迭代次数\")\n        break\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"迭代优化完成\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. 增量更新submission.csv函数"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def update_submission_incrementally(sample_status, data_dir, output_file=\"submission.csv\"):\n    \"\"\"\n    增量更新submission.csv文件\n    每次调用时重新生成整个文件，确保包含最新的所有结果\n    \n    Args:\n        sample_status: 样本状态字典，包含每个样本的最佳结构\n        data_dir: 数据目录路径\n        output_file: 输出文件名\n    \n    Returns:\n        pd.DataFrame: submission数据框\n    \"\"\"\n    # 获取ID前缀（A或B）\n    with open(data_dir / \"composition.json\", 'r') as f:\n        composition_dict = json.load(f)\n    prefix = next(iter(composition_dict))[0]  # 获取第一个ID的首字母\n    \n    # 准备submission数据\n    rows = []\n    \n    for sample_id, status in sample_status.items():\n        try:\n            structure = status['best_structure']\n            \n            if structure is not None:\n                # 转换为CIF格式\n                cif_str = structure.to(fmt=\"cif\")\n            else:\n                # 如果还没有结构，创建占位CIF\n                cif_str = f\"data_{sample_id}\\n_cell_length_a 5.0\\n_cell_length_b 5.0\\n_cell_length_c 5.0\\n_cell_angle_alpha 90\\n_cell_angle_beta 90\\n_cell_angle_gamma 90\\n\"\n            \n            rows.append({\n                'ID': sample_id,\n                'cif': cif_str\n            })\n        except Exception as e:\n            # 出错时创建占位CIF\n            min_cif = f\"data_{sample_id}\\n_cell_length_a 5.0\\n_cell_length_b 5.0\\n_cell_length_c 5.0\\n_cell_angle_alpha 90\\n_cell_angle_beta 90\\n_cell_angle_gamma 90\\n\"\n            rows.append({\n                'ID': sample_id,\n                'cif': min_cif\n            })\n    \n    # 创建DataFrame\n    submission_df = pd.DataFrame(rows)\n    \n    # 保存为CSV（覆盖原文件）\n    submission_df.to_csv(output_file, index=False)\n    \n    return submission_df\n\ndef log_submission_update(iteration, sample_status, submission_file=\"submission.csv\"):\n    \"\"\"\n    记录submission更新信息\n    \n    Args:\n        iteration: 当前迭代轮次（0表示初始推理）\n        sample_status: 样本状态字典\n        submission_file: submission文件路径\n    \"\"\"\n    satisfied_count = sum(1 for s in sample_status.values() if s['satisfied'])\n    total_count = len(sample_status)\n    \n    if iteration == 0:\n        print(f\"\\n📝 初始submission.csv已生成\")\n    else:\n        print(f\"\\n📝 submission.csv已更新 (迭代{iteration})\")\n    \n    print(f\"   满足要求: {satisfied_count}/{total_count} ({satisfied_count/total_count*100:.1f}%)\")\n    \n    if os.path.exists(submission_file):\n        file_size = os.path.getsize(submission_file) / 1024\n        print(f\"   文件大小: {file_size:.2f} KB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 14. 最终统计和验证"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 最终统计\nprint(\"\\n\" + \"=\"*60)\nprint(\"最终统计\")\nprint(\"=\"*60)\n\n# 计算各项统计指标\nsatisfied_samples = [s for s in sample_status.values() if s['satisfied']]\nunsatisfied_samples = [s for s in sample_status.values() if not s['satisfied']]\n\nprint(f\"\\n质量统计:\")\nprint(f\"  满足RWP<{RWP_THRESHOLD}: {len(satisfied_samples)}/{len(sample_status)} ({len(satisfied_samples)/len(sample_status)*100:.1f}%)\")\nprint(f\"  未满足要求: {len(unsatisfied_samples)}\")\n\nif satisfied_samples:\n    satisfied_rwps = [s['best_rwp'] for s in satisfied_samples]\n    print(f\"\\n满足要求样本的RWP:\")\n    print(f\"  最小: {np.min(satisfied_rwps):.4f}\")\n    print(f\"  最大: {np.max(satisfied_rwps):.4f}\")\n    print(f\"  平均: {np.mean(satisfied_rwps):.4f}\")\n\nif unsatisfied_samples:\n    unsatisfied_rwps = [s['best_rwp'] for s in unsatisfied_samples]\n    print(f\"\\n未满足要求样本的RWP:\")\n    print(f\"  最小: {np.min(unsatisfied_rwps):.4f}\")\n    print(f\"  最大: {np.max(unsatisfied_rwps):.4f}\")\n    print(f\"  平均: {np.mean(unsatisfied_rwps):.4f}\")\n\n# 尝试次数统计\nattempts_list = [s['attempts'] for s in sample_status.values()]\nprint(f\"\\n尝试次数统计:\")\nprint(f\"  最少: {np.min(attempts_list)}\")\nprint(f\"  最多: {np.max(attempts_list)}\")\nprint(f\"  平均: {np.mean(attempts_list):.1f}\")\nprint(f\"  达到上限({MAX_ATTEMPTS_PER_SAMPLE}次): {sum(1 for a in attempts_list if a >= MAX_ATTEMPTS_PER_SAMPLE)}\")\n\n# 运行时间\ntotal_time = time.time() - START_TIME\nprint(f\"\\n总运行时间: {total_time/3600:.2f}小时\")\n\n# 验证最终的提交文件\nprint(f\"\\n验证最终submission文件:\")\nif os.path.exists(SUBMISSION_FILE):\n    # 重新读取文件以验证\n    final_submission = pd.read_csv(SUBMISSION_FILE)\n    print(f\"  文件名: {SUBMISSION_FILE}\")\n    print(f\"  文件大小: {os.path.getsize(SUBMISSION_FILE) / 1024:.2f} KB\")\n    print(f\"  样本数: {len(final_submission)}\")\n    print(f\"  列名: {final_submission.columns.tolist()}\")\n    \n    # 检查是否有缺失值\n    missing = final_submission.isnull().sum()\n    if missing.any():\n        print(f\"\\n⚠️ 警告：发现缺失值！\")\n        print(missing[missing > 0])\n    else:\n        print(f\"  ✅ 没有缺失值\")\n    \n    # 检查ID是否完整\n    expected_ids = set(sample_status.keys())\n    actual_ids = set(final_submission['ID'].values)\n    if expected_ids == actual_ids:\n        print(f\"  ✅ 所有样本ID都已包含\")\n    else:\n        missing_ids = expected_ids - actual_ids\n        extra_ids = actual_ids - expected_ids\n        if missing_ids:\n            print(f\"  ⚠️ 缺少ID: {missing_ids}\")\n        if extra_ids:\n            print(f\"  ⚠️ 多余ID: {extra_ids}\")\nelse:\n    print(f\"  ❌ 文件不存在: {SUBMISSION_FILE}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"✅ 推理完成！submission.csv已在整个过程中实时更新\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 总结\n\n本notebook实现了迭代优化的推理流程，并**实时更新submission.csv**：\n\n### 核心流程\n1. ✅ **初始推理**：模型推理生成初始结构，立即保存submission.csv\n2. ✅ **质量评估**：使用RWP指标评估PXRD匹配质量\n3. ✅ **迭代优化**：\n   - 能量优化 + Rietveld精修\n   - **每轮迭代后立即更新submission.csv**\n   - 批量重新生成不满足要求的样本\n4. ✅ **终止条件**：\n   - 运行时间限制（5小时）\n   - 单样本尝试次数限制\n   - 全部满足要求\n\n### 关键改进\n- 🔄 **增量更新机制**：每次推理/优化后立即覆盖submission.csv\n- 📊 **实时进度反馈**：评测脚本可以随时读取最新结果\n- 🛡️ **断点续传支持**：即使中途中断，已有结果也保存在submission.csv中\n- 📝 **更新日志**：每次更新都记录状态信息（满足率、文件大小等）\n\n### 待实现部分\n- ⏳ 实际的模型推理\n- ⏳ PXRD计算（调用PXRDSimulator）\n- ⏳ 能量优化（GULP等）\n- ⏳ Rietveld精修（GSAS-II等）\n\n### 输出\n- ✅ 符合比赛要求的submission.csv（CIF格式）\n- ✅ **实时更新**：每轮推理后立即保存，评测脚本可及时读取\n- ✅ 详细的优化过程记录和统计"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}