{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ™¶ä½“ç»“æ„ç”Ÿæˆæ¨ç† Notebook - è¿­ä»£ä¼˜åŒ–ç‰ˆ\n",
    "\n",
    "æœ¬notebookå®ç°è¿­ä»£ä¼˜åŒ–çš„æ¨ç†æµç¨‹ï¼š\n",
    "\n",
    "## æ ¸å¿ƒæµç¨‹\n",
    "1. **åˆå§‹æ¨ç†**ï¼šæ¨¡å‹æ¨ç†ç”Ÿæˆåˆå§‹submission.csv\n",
    "2. **è´¨é‡è¯„ä¼°**ï¼šä½¿ç”¨RWPæŒ‡æ ‡è¯„ä¼°PXRDåŒ¹é…è´¨é‡\n",
    "3. **è¿­ä»£ä¼˜åŒ–å¾ªç¯**ï¼š\n",
    "   - è´¨é‡ä¸å¥½çš„æ ·æœ¬è¿›è¡Œåå¤„ç†ï¼ˆèƒ½é‡ä¼˜åŒ–â†’Rietveldç²¾ä¿®ï¼‰\n",
    "   - å¦‚æœè´¨é‡æ”¹å–„åˆ™æ›´æ–°submission.csv\n",
    "   - ä»ä¸æ»¡è¶³è¦æ±‚çš„æ‰¹é‡é‡æ–°ç”Ÿæˆ\n",
    "4. **ç»ˆæ­¢æ¡ä»¶**ï¼š\n",
    "   - æ€»è¿è¡Œæ—¶é—´è¶…è¿‡5å°æ—¶\n",
    "   - å•ä¸ªæ ·æœ¬å°è¯•æ¬¡æ•°è¶…é™\n",
    "   - æ‰€æœ‰æ ·æœ¬æ»¡è¶³è´¨é‡è¦æ±‚\n",
    "\n",
    "**æ³¨æ„**: è¿™ä¸ªnotebookè®¾è®¡ä¸ºå¯ç›´æ¥åœ¨æ¯”èµ›ç¯å¢ƒè¿è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å¯¼å…¥å¿…è¦çš„åº“å’Œè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\nimport sys\nimport time\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom tqdm.auto import tqdm\nfrom pymatgen.core import Structure, Lattice, Composition, Element\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„\nsys.path.append('.')  # æ·»åŠ æ ¹ç›®å½•\nsys.path.append('src')\n\n# å¯¼å…¥å¿…è¦çš„æ¨¡å—\nfrom src.trainer import CrystalGenerationModule\nfrom src.pxrd_simulator import PXRDSimulator\nfrom src.normalizer import LatticeNormalizer\n\n# è®¾ç½®éšæœºç§å­\nnp.random.seed(42)\ntorch.manual_seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(42)\n\nprint(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\nprint(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDAè®¾å¤‡: {torch.cuda.get_device_name(0)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. é…ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ•°æ®è·¯å¾„é…ç½®\nDATA_DIR = Path(\"data/A_sample\")  # æ¯”èµ›æ•°æ®ç›®å½•\nCOMPOSITION_FILE = DATA_DIR / \"composition.json\"\nPATTERN_DIR = DATA_DIR / \"pattern\"\n\n# æ¨¡å‹è·¯å¾„ - ä½¿ç”¨å®é™…çš„checkpointè·¯å¾„\nMODEL_PATH = \"outputs/transformer_cfm_20250828_144134/checkpoints/last.ckpt\"\n\n# è¾“å‡ºæ–‡ä»¶ï¼ˆå¿…é¡»åœ¨æ ¹ç›®å½•ï¼‰\nSUBMISSION_FILE = \"submission.csv\"\n\n# ä¼˜åŒ–å‚æ•°\nRWP_THRESHOLD = 0.15  # RWPè´¨é‡é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è®¤ä¸ºè´¨é‡åˆæ ¼\nMAX_TIME_HOURS = 5  # æœ€å¤§è¿è¡Œæ—¶é—´ï¼ˆå°æ—¶ï¼‰\nMAX_ATTEMPTS_PER_SAMPLE = 10  # æ¯ä¸ªæ ·æœ¬æœ€å¤§å°è¯•æ¬¡æ•°\nBATCH_SIZE = 32  # æ‰¹é‡é‡æ–°ç”Ÿæˆçš„å¤§å°\n\n# è®°å½•å¼€å§‹æ—¶é—´\nSTART_TIME = time.time()\nMAX_RUNTIME = MAX_TIME_HOURS * 3600  # è½¬æ¢ä¸ºç§’\n\nprint(f\"é…ç½®å‚æ•°ï¼š\")\nprint(f\"  æ¨¡å‹è·¯å¾„: {MODEL_PATH}\")\nprint(f\"  æ¨¡å‹å­˜åœ¨: {os.path.exists(MODEL_PATH)}\")\nprint(f\"  RWPé˜ˆå€¼: {RWP_THRESHOLD}\")\nprint(f\"  æœ€å¤§è¿è¡Œæ—¶é—´: {MAX_TIME_HOURS}å°æ—¶\")\nprint(f\"  å•æ ·æœ¬æœ€å¤§å°è¯•: {MAX_ATTEMPTS_PER_SAMPLE}æ¬¡\")\nprint(f\"  å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ•°æ®åŠ è½½å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xy_file(file_path):\n",
    "    \"\"\"è¯»å–.xyæ ¼å¼çš„PXRDæ•°æ®\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                intensity = float(parts[1])\n",
    "                data.append(intensity)\n",
    "    return np.array(data, dtype=np.float32)\n",
    "\n",
    "def parse_composition(comp_str):\n",
    "    \"\"\"è§£æç»„æˆå­—ç¬¦ä¸²ä¸ºåŸå­ç±»å‹å’Œæ•°é‡\"\"\"\n",
    "    comp = Composition(comp_str)\n",
    "    atom_list = []\n",
    "    \n",
    "    for element, count in comp.items():\n",
    "        atomic_num = Element(element).Z\n",
    "        atom_list.extend([atomic_num] * int(count))\n",
    "    \n",
    "    # å¡«å……åˆ°60ç»´\n",
    "    atom_types = np.zeros(60, dtype=np.int32)\n",
    "    atom_types[:len(atom_list)] = atom_list[:60]\n",
    "    \n",
    "    return len(atom_list), atom_types\n",
    "\n",
    "def load_competition_data(data_dir):\n",
    "    \"\"\"åŠ è½½æ¯”èµ›æ ¼å¼æ•°æ®\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # è¯»å–composition\n",
    "    with open(data_dir / \"composition.json\", 'r') as f:\n",
    "        compositions = json.load(f)\n",
    "    \n",
    "    # å‡†å¤‡æ•°æ®åˆ—è¡¨\n",
    "    data_list = []\n",
    "    \n",
    "    for sample_id, comp_info in tqdm(compositions.items(), desc=\"åŠ è½½æ•°æ®\"):\n",
    "        # è·å–ç»„æˆä¿¡æ¯\n",
    "        comp_list = comp_info[\"composition\"]\n",
    "        niggli_comp = comp_list[0]\n",
    "        primitive_comp = comp_list[1] if len(comp_list) > 1 else comp_list[0]\n",
    "        \n",
    "        # è§£æåŸå­ä¿¡æ¯\n",
    "        num_atoms, atom_types = parse_composition(niggli_comp)\n",
    "        \n",
    "        # è¯»å–PXRDæ•°æ®\n",
    "        pattern_file = data_dir / \"pattern\" / f\"{sample_id}.xy\"\n",
    "        if pattern_file.exists():\n",
    "            pxrd = read_xy_file(pattern_file)\n",
    "            # ç¡®ä¿é•¿åº¦ä¸º11501\n",
    "            if len(pxrd) < 11501:\n",
    "                pxrd_full = np.zeros(11501, dtype=np.float32)\n",
    "                pxrd_full[:len(pxrd)] = pxrd\n",
    "                pxrd = pxrd_full\n",
    "            elif len(pxrd) > 11501:\n",
    "                pxrd = pxrd[:11501]\n",
    "        else:\n",
    "            pxrd = np.zeros(11501, dtype=np.float32)\n",
    "        \n",
    "        data_list.append({\n",
    "            'id': sample_id,\n",
    "            'niggli_comp': niggli_comp,\n",
    "            'primitive_comp': primitive_comp,\n",
    "            'atom_types': atom_types,\n",
    "            'num_atoms': num_atoms,\n",
    "            'pxrd': pxrd  # è§‚æµ‹çš„PXRDè°±\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ¯”èµ›æ•°æ®\n",
    "df = load_competition_data(DATA_DIR)\n",
    "print(f\"\\nåŠ è½½äº† {len(df)} ä¸ªæ ·æœ¬\")\n",
    "print(f\"æ•°æ®åˆ—: {df.columns.tolist()}\")\n",
    "print(f\"\\nå‰5ä¸ªæ ·æœ¬:\")\n",
    "print(df[['id', 'niggli_comp', 'num_atoms']].head())\n",
    "\n",
    "# åˆå§‹åŒ–æ ·æœ¬çŠ¶æ€è¿½è¸ª\n",
    "sample_status = {\n",
    "    sample_id: {\n",
    "        'attempts': 0,\n",
    "        'best_rwp': float('inf'),\n",
    "        'best_structure': None,\n",
    "        'satisfied': False\n",
    "    }\n",
    "    for sample_id in df['id']\n",
    "}\n",
    "\n",
    "print(f\"\\nåˆå§‹åŒ–äº† {len(sample_status)} ä¸ªæ ·æœ¬çš„çŠ¶æ€è¿½è¸ª\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ¨¡å‹å’Œæ¨ç†å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# åŠ è½½æ¨¡å‹å’Œåˆå§‹åŒ–å·¥å…·\ndef load_model(model_path):\n    \"\"\"\n    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹\n    \n    Args:\n        model_path: checkpointæ–‡ä»¶è·¯å¾„\n        \n    Returns:\n        åŠ è½½å¥½çš„Lightningæ¨¡å—\n    \"\"\"\n    print(f\"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}\")\n    \n    # ä»checkpointåŠ è½½æ¨¡å‹\n    model = CrystalGenerationModule.load_from_checkpoint(\n        model_path,\n        map_location='cuda' if torch.cuda.is_available() else 'cpu'\n    )\n    \n    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n    model.eval()\n    \n    # ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    \n    print(f\"æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {device}\")\n    return model\n\ndef prepare_batch_for_model(sample_df, device):\n    \"\"\"\n    å‡†å¤‡æ¨¡å‹è¾“å…¥æ‰¹æ¬¡\n    \n    Args:\n        sample_df: åŒ…å«æ ·æœ¬æ•°æ®çš„DataFrame\n        device: è®¡ç®—è®¾å¤‡\n        \n    Returns:\n        dict: æ¨¡å‹è¾“å…¥æ‰¹æ¬¡\n    \"\"\"\n    batch = {\n        'comp': torch.tensor(np.stack(sample_df['atom_types'].values), dtype=torch.float32).to(device),\n        'pxrd': torch.tensor(np.stack(sample_df['pxrd'].values), dtype=torch.float32).to(device),\n        'num_atoms': torch.tensor(sample_df['num_atoms'].values, dtype=torch.long).to(device),\n    }\n    return batch\n\ndef generate_crystal_structure(sample, model, lattice_normalizer, pxrd_simulator):\n    \"\"\"\n    ä½¿ç”¨æ¨¡å‹ç”Ÿæˆæ™¶ä½“ç»“æ„\n    \n    Args:\n        sample: åŒ…å«pxrdã€atom_typesã€num_atomsç­‰ä¿¡æ¯çš„æ ·æœ¬\n        model: è®­ç»ƒå¥½çš„æ¨¡å‹\n        lattice_normalizer: æ™¶æ ¼å½’ä¸€åŒ–å™¨\n        pxrd_simulator: PXRDä»¿çœŸå™¨\n    \n    Returns:\n        Structureå¯¹è±¡\n    \"\"\"\n    device = next(model.parameters()).device\n    \n    # å‡†å¤‡å•ä¸ªæ ·æœ¬çš„æ‰¹æ¬¡\n    batch = {\n        'comp': torch.tensor(sample['atom_types'], dtype=torch.float32).unsqueeze(0).to(device),\n        'pxrd': torch.tensor(sample['pxrd'], dtype=torch.float32).unsqueeze(0).to(device),\n        'num_atoms': torch.tensor([sample['num_atoms']], dtype=torch.long).to(device),\n    }\n    \n    # æ¨¡å‹æ¨ç†\n    with torch.no_grad():\n        # ä½¿ç”¨flowçš„sampleæ–¹æ³•ç”Ÿæˆ\n        generated = model.flow.sample(batch)  # [1, 63, 3]\n        \n    # è½¬æ¢åˆ°CPUå¹¶æå–æ•°æ®\n    generated = generated.cpu().numpy()[0]  # [63, 3]\n    \n    # åˆ†ç¦»æ™¶æ ¼å’Œåˆ†æ•°åæ ‡\n    lattice_vectors = generated[:3, :]  # [3, 3] å½’ä¸€åŒ–çš„æ™¶æ ¼å‘é‡\n    frac_coords = generated[3:3+sample['num_atoms'], :]  # [num_atoms, 3]\n    \n    # åå½’ä¸€åŒ–æ™¶æ ¼å‚æ•°\n    lattice_matrix = lattice_normalizer.denormalize_lattice(\n        torch.tensor(lattice_vectors, dtype=torch.float32).unsqueeze(0)\n    ).numpy()[0]\n    \n    # ç¡®ä¿åˆ†æ•°åæ ‡åœ¨[0,1]èŒƒå›´å†…\n    frac_coords = np.mod(frac_coords, 1.0)\n    \n    # è·å–å…ƒç´ åˆ—è¡¨\n    species = []\n    for i in range(sample['num_atoms']):\n        atomic_num = int(sample['atom_types'][i])\n        if atomic_num > 0:\n            species.append(Element.from_Z(atomic_num))\n    \n    # åˆ›å»ºStructureå¯¹è±¡\n    try:\n        lattice = Lattice(lattice_matrix)\n        structure = Structure(\n            lattice=lattice,\n            species=species,\n            coords=frac_coords,\n            coords_are_cartesian=False\n        )\n    except Exception as e:\n        print(f\"åˆ›å»ºStructureå¤±è´¥: {e}\")\n        # å›é€€åˆ°éšæœºç”Ÿæˆ\n        return generate_random_structure(sample)\n    \n    return structure\n\ndef generate_random_structure(sample):\n    \"\"\"\n    ç”Ÿæˆéšæœºæ™¶ä½“ç»“æ„ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰\n    \n    Args:\n        sample: æ ·æœ¬æ•°æ®\n        \n    Returns:\n        Structureå¯¹è±¡\n    \"\"\"\n    num_atoms = sample['num_atoms']\n    \n    # éšæœºæ™¶æ ¼å‚æ•°\n    a = np.random.uniform(3, 10)\n    b = np.random.uniform(3, 10)\n    c = np.random.uniform(3, 10)\n    alpha = np.random.uniform(60, 120)\n    beta = np.random.uniform(60, 120)\n    gamma = np.random.uniform(60, 120)\n    \n    lattice = Lattice.from_parameters(a, b, c, alpha, beta, gamma)\n    frac_coords = np.random.rand(num_atoms, 3)\n    \n    species = []\n    for i in range(num_atoms):\n        atomic_num = int(sample['atom_types'][i])\n        if atomic_num > 0:\n            species.append(Element.from_Z(atomic_num))\n    \n    return Structure(\n        lattice=lattice,\n        species=species,\n        coords=frac_coords,\n        coords_are_cartesian=False\n    )\n\n# åŠ è½½æ¨¡å‹å’Œåˆå§‹åŒ–å·¥å…·\ntry:\n    model = load_model(MODEL_PATH)\n    lattice_normalizer = LatticeNormalizer()\n    pxrd_simulator = PXRDSimulator()\n    print(\"âœ… æ¨¡å‹å’Œå·¥å…·åˆå§‹åŒ–æˆåŠŸ\")\nexcept Exception as e:\n    print(f\"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n    print(\"å°†ä½¿ç”¨éšæœºç”Ÿæˆä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ\")\n    model = None\n    lattice_normalizer = None\n    pxrd_simulator = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PXRDè®¡ç®—å’Œè´¨é‡è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def calculate_pxrd(structure, pxrd_simulator=None):\n    \"\"\"\n    è®¡ç®—æ™¶ä½“ç»“æ„çš„PXRDè°±\n    \n    Args:\n        structure: pymatgen Structureå¯¹è±¡\n        pxrd_simulator: PXRDä»¿çœŸå™¨å®ä¾‹\n    \n    Returns:\n        np.array: 11501ç»´çš„PXRDå¼ºåº¦æ•°ç»„\n    \"\"\"\n    if pxrd_simulator is None:\n        # å¦‚æœæ²¡æœ‰æä¾›simulatorï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„\n        from src.PXRDSimulator import PXRDSimulator\n        pxrd_simulator = PXRDSimulator()\n    \n    try:\n        # ä½¿ç”¨PXRDSimulatorè®¡ç®—PXRD\n        pxrd_calc = pxrd_simulator.get_pattern(structure)\n        \n        # ç¡®ä¿è¿”å›11501ç»´\n        if len(pxrd_calc) < 11501:\n            pxrd_full = np.zeros(11501, dtype=np.float32)\n            pxrd_full[:len(pxrd_calc)] = pxrd_calc\n            pxrd_calc = pxrd_full\n        elif len(pxrd_calc) > 11501:\n            pxrd_calc = pxrd_calc[:11501]\n            \n        return pxrd_calc\n        \n    except Exception as e:\n        print(f\"PXRDè®¡ç®—å¤±è´¥: {e}\")\n        # è¿”å›éšæœºPXRDä½œä¸ºå¤‡ç”¨\n        pxrd_calc = np.random.rand(11501) * 100\n        pxrd_calc[pxrd_calc < 10] = 0\n        return pxrd_calc\n\ndef evaluate_structure_quality(structure, observed_pxrd, pxrd_simulator=None):\n    \"\"\"\n    è¯„ä¼°ç”Ÿæˆç»“æ„çš„è´¨é‡\n    \n    Args:\n        structure: ç”Ÿæˆçš„Structureå¯¹è±¡\n        observed_pxrd: è§‚æµ‹çš„PXRDè°±\n        pxrd_simulator: PXRDä»¿çœŸå™¨å®ä¾‹\n    \n    Returns:\n        float: RWPå€¼ï¼ˆè¶Šå°è¶Šå¥½ï¼‰\n    \"\"\"\n    # è®¡ç®—ç”Ÿæˆç»“æ„çš„PXRD\n    calculated_pxrd = calculate_pxrd(structure, pxrd_simulator)\n    \n    # ç®€å•çš„RWPè®¡ç®—ï¼ˆå¦‚æœæ²¡æœ‰ä¸“é—¨çš„metricsæ¨¡å—ï¼‰\n    try:\n        from src.metrics import rwp\n        rwp_value = rwp(calculated_pxrd, observed_pxrd)\n    except ImportError:\n        # å¤‡ç”¨RWPè®¡ç®—\n        diff = calculated_pxrd - observed_pxrd\n        weighted_diff = diff * np.sqrt(np.maximum(observed_pxrd, 1e-10))\n        rwp_value = np.sqrt(np.sum(weighted_diff**2) / np.sum(observed_pxrd**2 + 1e-10))\n    \n    return rwp_value"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. åå¤„ç†å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_optimization(structure):\n",
    "    \"\"\"\n",
    "    èƒ½é‡ä¼˜åŒ–\n",
    "    \n",
    "    Args:\n",
    "        structure: å¾…ä¼˜åŒ–çš„Structureå¯¹è±¡\n",
    "    \n",
    "    Returns:\n",
    "        Structure: ä¼˜åŒ–åçš„ç»“æ„\n",
    "    \"\"\"\n",
    "    # TODO: å®ç°èƒ½é‡ä¼˜åŒ–\n",
    "    # å¯ä»¥ä½¿ç”¨GULPã€VASPã€æˆ–æœºå™¨å­¦ä¹ åŠ¿å‡½æ•°ç­‰\n",
    "    \n",
    "    # å ä½ï¼šç¨å¾®è°ƒæ•´æ™¶æ ¼å‚æ•°æ¨¡æ‹Ÿä¼˜åŒ–\n",
    "    new_lattice = structure.lattice.matrix * np.random.uniform(0.98, 1.02)\n",
    "    optimized = Structure(\n",
    "        lattice=Lattice(new_lattice),\n",
    "        species=structure.species,\n",
    "        coords=structure.frac_coords,\n",
    "        coords_are_cartesian=False\n",
    "    )\n",
    "    \n",
    "    return optimized\n",
    "\n",
    "def rietveld_refinement(structure, observed_pxrd):\n",
    "    \"\"\"\n",
    "    Rietveldç²¾ä¿®\n",
    "    \n",
    "    Args:\n",
    "        structure: å¾…ç²¾ä¿®çš„Structureå¯¹è±¡\n",
    "        observed_pxrd: è§‚æµ‹çš„PXRDè°±\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (ç²¾ä¿®åçš„Structure, æ˜¯å¦éœ€è¦ç²¾ä¿®)\n",
    "    \"\"\"\n",
    "    # åˆ¤æ–­æ˜¯å¦éœ€è¦ç²¾ä¿®\n",
    "    current_rwp = evaluate_structure_quality(structure, observed_pxrd)\n",
    "    needs_refinement = current_rwp > RWP_THRESHOLD * 1.5  # å¦‚æœRWPè¾ƒé«˜åˆ™éœ€è¦ç²¾ä¿®\n",
    "    \n",
    "    if not needs_refinement:\n",
    "        return structure, False\n",
    "    \n",
    "    # TODO: å®ç°Rietveldç²¾ä¿®\n",
    "    # å¯ä»¥ä½¿ç”¨GSAS-IIã€TOPASã€FullProfç­‰\n",
    "    \n",
    "    # å ä½ï¼šç¨å¾®è°ƒæ•´åŸå­ä½ç½®æ¨¡æ‹Ÿç²¾ä¿®\n",
    "    new_coords = structure.frac_coords + np.random.randn(*structure.frac_coords.shape) * 0.01\n",
    "    new_coords = np.clip(new_coords, 0, 1)  # ç¡®ä¿åœ¨[0,1]èŒƒå›´å†…\n",
    "    \n",
    "    refined = Structure(\n",
    "        lattice=structure.lattice,\n",
    "        species=structure.species,\n",
    "        coords=new_coords,\n",
    "        coords_are_cartesian=False\n",
    "    )\n",
    "    \n",
    "    return refined, True\n",
    "\n",
    "def post_process_structure(structure, observed_pxrd):\n",
    "    \"\"\"\n",
    "    å®Œæ•´çš„åå¤„ç†æµç¨‹\n",
    "    \n",
    "    Args:\n",
    "        structure: å¾…å¤„ç†çš„Structureå¯¹è±¡\n",
    "        observed_pxrd: è§‚æµ‹çš„PXRDè°±\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (å¤„ç†åçš„Structure, æœ€ç»ˆRWPå€¼)\n",
    "    \"\"\"\n",
    "    # 1. èƒ½é‡ä¼˜åŒ–\n",
    "    optimized = energy_optimization(structure)\n",
    "    rwp_after_opt = evaluate_structure_quality(optimized, observed_pxrd)\n",
    "    \n",
    "    # 2. Rietveldç²¾ä¿®ï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "    refined, was_refined = rietveld_refinement(optimized, observed_pxrd)\n",
    "    \n",
    "    if was_refined:\n",
    "        rwp_after_refine = evaluate_structure_quality(refined, observed_pxrd)\n",
    "        return refined, rwp_after_refine\n",
    "    else:\n",
    "        return optimized, rwp_after_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ç»ˆæ­¢æ¡ä»¶æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_termination_conditions(sample_status):\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥æ˜¯å¦æ»¡è¶³ç»ˆæ­¢æ¡ä»¶\n",
    "    \n",
    "    ç»ˆæ­¢æ¡ä»¶ï¼š\n",
    "    1. è¿è¡Œæ—¶é—´è¶…è¿‡5å°æ—¶\n",
    "    2. æ‰€æœ‰æ ·æœ¬éƒ½æ»¡è¶³è´¨é‡è¦æ±‚æˆ–è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (æ˜¯å¦ç»ˆæ­¢, ç»ˆæ­¢åŸå› )\n",
    "    \"\"\"\n",
    "    # æ£€æŸ¥è¿è¡Œæ—¶é—´\n",
    "    elapsed_time = time.time() - START_TIME\n",
    "    if elapsed_time > MAX_RUNTIME:\n",
    "        return True, f\"è¾¾åˆ°æœ€å¤§è¿è¡Œæ—¶é—´ {MAX_TIME_HOURS} å°æ—¶\"\n",
    "    \n",
    "    # æ£€æŸ¥æ‰€æœ‰æ ·æœ¬çŠ¶æ€\n",
    "    all_done = all(\n",
    "        status['satisfied'] or status['attempts'] >= MAX_ATTEMPTS_PER_SAMPLE\n",
    "        for status in sample_status.values()\n",
    "    )\n",
    "    \n",
    "    if all_done:\n",
    "        satisfied_count = sum(1 for s in sample_status.values() if s['satisfied'])\n",
    "        return True, f\"æ‰€æœ‰æ ·æœ¬å¤„ç†å®Œæˆï¼ˆ{satisfied_count}/{len(sample_status)}æ»¡è¶³è¦æ±‚ï¼‰\"\n",
    "    \n",
    "    return False, None\n",
    "\n",
    "def get_samples_to_regenerate(sample_status, batch_size=32):\n",
    "    \"\"\"\n",
    "    è·å–éœ€è¦é‡æ–°ç”Ÿæˆçš„æ ·æœ¬\n",
    "    \n",
    "    Args:\n",
    "        sample_status: æ ·æœ¬çŠ¶æ€å­—å…¸\n",
    "        batch_size: æ‰¹æ¬¡å¤§å°\n",
    "    \n",
    "    Returns:\n",
    "        list: éœ€è¦é‡æ–°ç”Ÿæˆçš„æ ·æœ¬IDåˆ—è¡¨\n",
    "    \"\"\"\n",
    "    # æ‰¾å‡ºæœªæ»¡è¶³è¦æ±‚ä¸”æœªè¶…è¿‡å°è¯•æ¬¡æ•°çš„æ ·æœ¬\n",
    "    candidates = [\n",
    "        sample_id for sample_id, status in sample_status.items()\n",
    "        if not status['satisfied'] and status['attempts'] < MAX_ATTEMPTS_PER_SAMPLE\n",
    "    ]\n",
    "    \n",
    "    # æŒ‰RWPå€¼æ’åºï¼Œä¼˜å…ˆå¤„ç†è´¨é‡æœ€å·®çš„\n",
    "    candidates.sort(key=lambda x: sample_status[x]['best_rwp'], reverse=True)\n",
    "    \n",
    "    return candidates[:batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12. åˆå§‹æ¨ç†ï¼ˆå¸¦å®æ—¶ä¿å­˜ï¼‰"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*60)\nprint(\"é˜¶æ®µ1ï¼šåˆå§‹æ¨ç†\")\nprint(\"=\"*60)\n\ninitial_predictions = {}\n\nfor idx, row in tqdm(df.iterrows(), total=len(df), desc=\"åˆå§‹æ¨ç†\"):\n    sample_id = row['id']\n    \n    # ç”Ÿæˆåˆå§‹ç»“æ„\n    if model is not None:\n        structure = generate_crystal_structure(row, model, lattice_normalizer, pxrd_simulator)\n    else:\n        structure = generate_random_structure(row)\n    \n    # è¯„ä¼°è´¨é‡\n    rwp_value = evaluate_structure_quality(structure, row['pxrd'], pxrd_simulator)\n    \n    # æ›´æ–°çŠ¶æ€\n    sample_status[sample_id]['attempts'] = 1\n    sample_status[sample_id]['best_rwp'] = rwp_value\n    sample_status[sample_id]['best_structure'] = structure\n    sample_status[sample_id]['satisfied'] = rwp_value < RWP_THRESHOLD\n    \n    initial_predictions[sample_id] = structure\n\n# ç»Ÿè®¡åˆå§‹ç»“æœ\nsatisfied_count = sum(1 for s in sample_status.values() if s['satisfied'])\navg_rwp = np.mean([s['best_rwp'] for s in sample_status.values()])\n\nprint(f\"\\nåˆå§‹æ¨ç†ç»“æœ:\")\nprint(f\"  æ»¡è¶³è¦æ±‚: {satisfied_count}/{len(sample_status)} ({satisfied_count/len(sample_status)*100:.1f}%)\")\nprint(f\"  å¹³å‡RWP: {avg_rwp:.4f}\")\nprint(f\"  RWPé˜ˆå€¼: {RWP_THRESHOLD}\")\n\n# ç«‹å³ä¿å­˜åˆå§‹æ¨ç†ç»“æœåˆ°submission.csv\nsubmission_df = update_submission_incrementally(sample_status, DATA_DIR, SUBMISSION_FILE)\nlog_submission_update(0, sample_status, SUBMISSION_FILE)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 13. è¿­ä»£ä¼˜åŒ–å¾ªç¯ï¼ˆå¸¦å®æ—¶ä¿å­˜ï¼‰"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*60)\nprint(\"é˜¶æ®µ2ï¼šè¿­ä»£ä¼˜åŒ–\")\nprint(\"=\"*60)\n\niteration = 0\nwhile True:\n    iteration += 1\n    \n    # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶\n    should_terminate, reason = check_termination_conditions(sample_status)\n    if should_terminate:\n        print(f\"\\nç»ˆæ­¢ä¼˜åŒ–: {reason}\")\n        break\n    \n    print(f\"\\n--- è¿­ä»£ {iteration} ---\")\n    elapsed = time.time() - START_TIME\n    print(f\"å·²è¿è¡Œ: {elapsed/3600:.2f}å°æ—¶\")\n    \n    # è·å–éœ€è¦ä¼˜åŒ–çš„æ ·æœ¬\n    samples_to_process = get_samples_to_regenerate(sample_status, BATCH_SIZE)\n    \n    if not samples_to_process:\n        print(\"æ²¡æœ‰éœ€è¦å¤„ç†çš„æ ·æœ¬\")\n        break\n    \n    print(f\"å¤„ç† {len(samples_to_process)} ä¸ªæ ·æœ¬\")\n    \n    # æ ‡è®°æ˜¯å¦æœ‰æ”¹è¿›\n    has_improvement = False\n    \n    # å¤„ç†æ¯ä¸ªæ ·æœ¬\n    for sample_id in tqdm(samples_to_process, desc=f\"è¿­ä»£{iteration}\"):\n        row = df[df['id'] == sample_id].iloc[0]\n        current_best = sample_status[sample_id]['best_structure']\n        current_rwp = sample_status[sample_id]['best_rwp']\n        initial_rwp = current_rwp  # è®°å½•æ”¹è¿›å‰çš„RWP\n        \n        # ç­–ç•¥1ï¼šåå¤„ç†å½“å‰æœ€ä½³ç»“æ„\n        if sample_status[sample_id]['attempts'] < MAX_ATTEMPTS_PER_SAMPLE // 2:\n            processed_structure, processed_rwp = post_process_structure(\n                current_best, row['pxrd']\n            )\n            \n            if processed_rwp < current_rwp:\n                sample_status[sample_id]['best_structure'] = processed_structure\n                sample_status[sample_id]['best_rwp'] = processed_rwp\n                sample_status[sample_id]['satisfied'] = processed_rwp < RWP_THRESHOLD\n                current_rwp = processed_rwp\n                has_improvement = True\n        \n        # ç­–ç•¥2ï¼šå¦‚æœè´¨é‡ä»ä¸æ»¡è¶³ï¼Œé‡æ–°ç”Ÿæˆ\n        if not sample_status[sample_id]['satisfied']:\n            if model is not None:\n                new_structure = generate_crystal_structure(row, model, lattice_normalizer, pxrd_simulator)\n            else:\n                new_structure = generate_random_structure(row)\n                \n            new_rwp = evaluate_structure_quality(new_structure, row['pxrd'], pxrd_simulator)\n            \n            # åå¤„ç†æ–°ç”Ÿæˆçš„ç»“æ„\n            processed_new, processed_new_rwp = post_process_structure(\n                new_structure, row['pxrd']\n            )\n            \n            # ä¿ç•™æœ€ä½³ç»“æœ\n            if processed_new_rwp < sample_status[sample_id]['best_rwp']:\n                sample_status[sample_id]['best_structure'] = processed_new\n                sample_status[sample_id]['best_rwp'] = processed_new_rwp\n                sample_status[sample_id]['satisfied'] = processed_new_rwp < RWP_THRESHOLD\n                has_improvement = True\n        \n        # æ›´æ–°å°è¯•æ¬¡æ•°\n        sample_status[sample_id]['attempts'] += 1\n    \n    # ç»Ÿè®¡å½“å‰çŠ¶æ€\n    satisfied_count = sum(1 for s in sample_status.values() if s['satisfied'])\n    avg_rwp = np.mean([s['best_rwp'] for s in sample_status.values()])\n    \n    print(f\"\\nè¿­ä»£{iteration}ç»“æœ:\")\n    print(f\"  æ»¡è¶³è¦æ±‚: {satisfied_count}/{len(sample_status)} ({satisfied_count/len(sample_status)*100:.1f}%)\")\n    print(f\"  å¹³å‡RWP: {avg_rwp:.4f}\")\n    \n    # æ¯æ¬¡è¿­ä»£åéƒ½æ›´æ–°submission.csvï¼ˆæ— è®ºæ˜¯å¦æœ‰æ”¹è¿›ï¼‰\n    submission_df = update_submission_incrementally(sample_status, DATA_DIR, SUBMISSION_FILE)\n    log_submission_update(iteration, sample_status, SUBMISSION_FILE)\n    \n    # å¦‚æœæœ‰æ”¹è¿›ï¼Œè¾“å‡ºæ”¹è¿›ä¿¡æ¯\n    if has_improvement:\n        print(\"  âœ¨ æœ¬è½®æœ‰æ ·æœ¬å¾—åˆ°æ”¹è¿›\")\n    \n    # é™åˆ¶è¿­ä»£æ¬¡æ•°ï¼ˆé¢å¤–ä¿æŠ¤ï¼‰\n    if iteration > 100:\n        print(\"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°\")\n        break\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"è¿­ä»£ä¼˜åŒ–å®Œæˆ\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. å¢é‡æ›´æ–°submission.csvå‡½æ•°"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def update_submission_incrementally(sample_status, data_dir, output_file=\"submission.csv\"):\n    \"\"\"\n    å¢é‡æ›´æ–°submission.csvæ–‡ä»¶\n    æ¯æ¬¡è°ƒç”¨æ—¶é‡æ–°ç”Ÿæˆæ•´ä¸ªæ–‡ä»¶ï¼Œç¡®ä¿åŒ…å«æœ€æ–°çš„æ‰€æœ‰ç»“æœ\n    \n    Args:\n        sample_status: æ ·æœ¬çŠ¶æ€å­—å…¸ï¼ŒåŒ…å«æ¯ä¸ªæ ·æœ¬çš„æœ€ä½³ç»“æ„\n        data_dir: æ•°æ®ç›®å½•è·¯å¾„\n        output_file: è¾“å‡ºæ–‡ä»¶å\n    \n    Returns:\n        pd.DataFrame: submissionæ•°æ®æ¡†\n    \"\"\"\n    # è·å–IDå‰ç¼€ï¼ˆAæˆ–Bï¼‰\n    with open(data_dir / \"composition.json\", 'r') as f:\n        composition_dict = json.load(f)\n    prefix = next(iter(composition_dict))[0]  # è·å–ç¬¬ä¸€ä¸ªIDçš„é¦–å­—æ¯\n    \n    # å‡†å¤‡submissionæ•°æ®\n    rows = []\n    \n    for sample_id, status in sample_status.items():\n        try:\n            structure = status['best_structure']\n            \n            if structure is not None:\n                # è½¬æ¢ä¸ºCIFæ ¼å¼\n                cif_str = structure.to(fmt=\"cif\")\n            else:\n                # å¦‚æœè¿˜æ²¡æœ‰ç»“æ„ï¼Œåˆ›å»ºå ä½CIF\n                cif_str = f\"data_{sample_id}\\n_cell_length_a 5.0\\n_cell_length_b 5.0\\n_cell_length_c 5.0\\n_cell_angle_alpha 90\\n_cell_angle_beta 90\\n_cell_angle_gamma 90\\n\"\n            \n            rows.append({\n                'ID': sample_id,\n                'cif': cif_str\n            })\n        except Exception as e:\n            # å‡ºé”™æ—¶åˆ›å»ºå ä½CIF\n            min_cif = f\"data_{sample_id}\\n_cell_length_a 5.0\\n_cell_length_b 5.0\\n_cell_length_c 5.0\\n_cell_angle_alpha 90\\n_cell_angle_beta 90\\n_cell_angle_gamma 90\\n\"\n            rows.append({\n                'ID': sample_id,\n                'cif': min_cif\n            })\n    \n    # åˆ›å»ºDataFrame\n    submission_df = pd.DataFrame(rows)\n    \n    # ä¿å­˜ä¸ºCSVï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰\n    submission_df.to_csv(output_file, index=False)\n    \n    return submission_df\n\ndef log_submission_update(iteration, sample_status, submission_file=\"submission.csv\"):\n    \"\"\"\n    è®°å½•submissionæ›´æ–°ä¿¡æ¯\n    \n    Args:\n        iteration: å½“å‰è¿­ä»£è½®æ¬¡ï¼ˆ0è¡¨ç¤ºåˆå§‹æ¨ç†ï¼‰\n        sample_status: æ ·æœ¬çŠ¶æ€å­—å…¸\n        submission_file: submissionæ–‡ä»¶è·¯å¾„\n    \"\"\"\n    satisfied_count = sum(1 for s in sample_status.values() if s['satisfied'])\n    total_count = len(sample_status)\n    \n    if iteration == 0:\n        print(f\"\\nğŸ“ åˆå§‹submission.csvå·²ç”Ÿæˆ\")\n    else:\n        print(f\"\\nğŸ“ submission.csvå·²æ›´æ–° (è¿­ä»£{iteration})\")\n    \n    print(f\"   æ»¡è¶³è¦æ±‚: {satisfied_count}/{total_count} ({satisfied_count/total_count*100:.1f}%)\")\n    \n    if os.path.exists(submission_file):\n        file_size = os.path.getsize(submission_file) / 1024\n        print(f\"   æ–‡ä»¶å¤§å°: {file_size:.2f} KB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 14. æœ€ç»ˆç»Ÿè®¡å’ŒéªŒè¯"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æœ€ç»ˆç»Ÿè®¡\nprint(\"\\n\" + \"=\"*60)\nprint(\"æœ€ç»ˆç»Ÿè®¡\")\nprint(\"=\"*60)\n\n# è®¡ç®—å„é¡¹ç»Ÿè®¡æŒ‡æ ‡\nsatisfied_samples = [s for s in sample_status.values() if s['satisfied']]\nunsatisfied_samples = [s for s in sample_status.values() if not s['satisfied']]\n\nprint(f\"\\nè´¨é‡ç»Ÿè®¡:\")\nprint(f\"  æ»¡è¶³RWP<{RWP_THRESHOLD}: {len(satisfied_samples)}/{len(sample_status)} ({len(satisfied_samples)/len(sample_status)*100:.1f}%)\")\nprint(f\"  æœªæ»¡è¶³è¦æ±‚: {len(unsatisfied_samples)}\")\n\nif satisfied_samples:\n    satisfied_rwps = [s['best_rwp'] for s in satisfied_samples]\n    print(f\"\\næ»¡è¶³è¦æ±‚æ ·æœ¬çš„RWP:\")\n    print(f\"  æœ€å°: {np.min(satisfied_rwps):.4f}\")\n    print(f\"  æœ€å¤§: {np.max(satisfied_rwps):.4f}\")\n    print(f\"  å¹³å‡: {np.mean(satisfied_rwps):.4f}\")\n\nif unsatisfied_samples:\n    unsatisfied_rwps = [s['best_rwp'] for s in unsatisfied_samples]\n    print(f\"\\næœªæ»¡è¶³è¦æ±‚æ ·æœ¬çš„RWP:\")\n    print(f\"  æœ€å°: {np.min(unsatisfied_rwps):.4f}\")\n    print(f\"  æœ€å¤§: {np.max(unsatisfied_rwps):.4f}\")\n    print(f\"  å¹³å‡: {np.mean(unsatisfied_rwps):.4f}\")\n\n# å°è¯•æ¬¡æ•°ç»Ÿè®¡\nattempts_list = [s['attempts'] for s in sample_status.values()]\nprint(f\"\\nå°è¯•æ¬¡æ•°ç»Ÿè®¡:\")\nprint(f\"  æœ€å°‘: {np.min(attempts_list)}\")\nprint(f\"  æœ€å¤š: {np.max(attempts_list)}\")\nprint(f\"  å¹³å‡: {np.mean(attempts_list):.1f}\")\nprint(f\"  è¾¾åˆ°ä¸Šé™({MAX_ATTEMPTS_PER_SAMPLE}æ¬¡): {sum(1 for a in attempts_list if a >= MAX_ATTEMPTS_PER_SAMPLE)}\")\n\n# è¿è¡Œæ—¶é—´\ntotal_time = time.time() - START_TIME\nprint(f\"\\næ€»è¿è¡Œæ—¶é—´: {total_time/3600:.2f}å°æ—¶\")\n\n# éªŒè¯æœ€ç»ˆçš„æäº¤æ–‡ä»¶\nprint(f\"\\néªŒè¯æœ€ç»ˆsubmissionæ–‡ä»¶:\")\nif os.path.exists(SUBMISSION_FILE):\n    # é‡æ–°è¯»å–æ–‡ä»¶ä»¥éªŒè¯\n    final_submission = pd.read_csv(SUBMISSION_FILE)\n    print(f\"  æ–‡ä»¶å: {SUBMISSION_FILE}\")\n    print(f\"  æ–‡ä»¶å¤§å°: {os.path.getsize(SUBMISSION_FILE) / 1024:.2f} KB\")\n    print(f\"  æ ·æœ¬æ•°: {len(final_submission)}\")\n    print(f\"  åˆ—å: {final_submission.columns.tolist()}\")\n    \n    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼\n    missing = final_submission.isnull().sum()\n    if missing.any():\n        print(f\"\\nâš ï¸ è­¦å‘Šï¼šå‘ç°ç¼ºå¤±å€¼ï¼\")\n        print(missing[missing > 0])\n    else:\n        print(f\"  âœ… æ²¡æœ‰ç¼ºå¤±å€¼\")\n    \n    # æ£€æŸ¥IDæ˜¯å¦å®Œæ•´\n    expected_ids = set(sample_status.keys())\n    actual_ids = set(final_submission['ID'].values)\n    if expected_ids == actual_ids:\n        print(f\"  âœ… æ‰€æœ‰æ ·æœ¬IDéƒ½å·²åŒ…å«\")\n    else:\n        missing_ids = expected_ids - actual_ids\n        extra_ids = actual_ids - expected_ids\n        if missing_ids:\n            print(f\"  âš ï¸ ç¼ºå°‘ID: {missing_ids}\")\n        if extra_ids:\n            print(f\"  âš ï¸ å¤šä½™ID: {extra_ids}\")\nelse:\n    print(f\"  âŒ æ–‡ä»¶ä¸å­˜åœ¨: {SUBMISSION_FILE}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… æ¨ç†å®Œæˆï¼submission.csvå·²åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­å®æ—¶æ›´æ–°\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## æ€»ç»“\n\næœ¬notebookå®ç°äº†è¿­ä»£ä¼˜åŒ–çš„æ¨ç†æµç¨‹ï¼Œå¹¶**å®æ—¶æ›´æ–°submission.csv**ï¼š\n\n### æ ¸å¿ƒæµç¨‹\n1. âœ… **åˆå§‹æ¨ç†**ï¼šæ¨¡å‹æ¨ç†ç”Ÿæˆåˆå§‹ç»“æ„ï¼Œç«‹å³ä¿å­˜submission.csv\n2. âœ… **è´¨é‡è¯„ä¼°**ï¼šä½¿ç”¨RWPæŒ‡æ ‡è¯„ä¼°PXRDåŒ¹é…è´¨é‡\n3. âœ… **è¿­ä»£ä¼˜åŒ–**ï¼š\n   - èƒ½é‡ä¼˜åŒ– + Rietveldç²¾ä¿®\n   - **æ¯è½®è¿­ä»£åç«‹å³æ›´æ–°submission.csv**\n   - æ‰¹é‡é‡æ–°ç”Ÿæˆä¸æ»¡è¶³è¦æ±‚çš„æ ·æœ¬\n4. âœ… **ç»ˆæ­¢æ¡ä»¶**ï¼š\n   - è¿è¡Œæ—¶é—´é™åˆ¶ï¼ˆ5å°æ—¶ï¼‰\n   - å•æ ·æœ¬å°è¯•æ¬¡æ•°é™åˆ¶\n   - å…¨éƒ¨æ»¡è¶³è¦æ±‚\n\n### å…³é”®æ”¹è¿›\n- ğŸ”„ **å¢é‡æ›´æ–°æœºåˆ¶**ï¼šæ¯æ¬¡æ¨ç†/ä¼˜åŒ–åç«‹å³è¦†ç›–submission.csv\n- ğŸ“Š **å®æ—¶è¿›åº¦åé¦ˆ**ï¼šè¯„æµ‹è„šæœ¬å¯ä»¥éšæ—¶è¯»å–æœ€æ–°ç»“æœ\n- ğŸ›¡ï¸ **æ–­ç‚¹ç»­ä¼ æ”¯æŒ**ï¼šå³ä½¿ä¸­é€”ä¸­æ–­ï¼Œå·²æœ‰ç»“æœä¹Ÿä¿å­˜åœ¨submission.csvä¸­\n- ğŸ“ **æ›´æ–°æ—¥å¿—**ï¼šæ¯æ¬¡æ›´æ–°éƒ½è®°å½•çŠ¶æ€ä¿¡æ¯ï¼ˆæ»¡è¶³ç‡ã€æ–‡ä»¶å¤§å°ç­‰ï¼‰\n\n### å¾…å®ç°éƒ¨åˆ†\n- â³ å®é™…çš„æ¨¡å‹æ¨ç†\n- â³ PXRDè®¡ç®—ï¼ˆè°ƒç”¨PXRDSimulatorï¼‰\n- â³ èƒ½é‡ä¼˜åŒ–ï¼ˆGULPç­‰ï¼‰\n- â³ Rietveldç²¾ä¿®ï¼ˆGSAS-IIç­‰ï¼‰\n\n### è¾“å‡º\n- âœ… ç¬¦åˆæ¯”èµ›è¦æ±‚çš„submission.csvï¼ˆCIFæ ¼å¼ï¼‰\n- âœ… **å®æ—¶æ›´æ–°**ï¼šæ¯è½®æ¨ç†åç«‹å³ä¿å­˜ï¼Œè¯„æµ‹è„šæœ¬å¯åŠæ—¶è¯»å–\n- âœ… è¯¦ç»†çš„ä¼˜åŒ–è¿‡ç¨‹è®°å½•å’Œç»Ÿè®¡"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}