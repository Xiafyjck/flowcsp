{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 比赛提交文件生成\n",
    "\n",
    "本notebook用于处理比赛规定的数据格式，进行模型推理，并生成最终的submission.csv文件。\n",
    "\n",
    "## 主要步骤：\n",
    "1. 加载测试数据（composition + PXRD）\n",
    "2. 加载训练好的模型\n",
    "3. 批量推理生成晶体结构\n",
    "4. 后处理优化（可选）\n",
    "5. 生成submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from pymatgen.core import Composition, Element, Structure, Lattice\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'使用设备: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据加载函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(data_path: str) -> Tuple[Dict, Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    加载测试数据，包括组成和PXRD谱\n",
    "    \n",
    "    Args:\n",
    "        data_path: 测试数据路径，如 'docs/data/test_v3/A'\n",
    "    \n",
    "    Returns:\n",
    "        compositions_dict: 组成信息字典 {sample_id: {\"composition\": [str, str]}}\n",
    "        pxrd_dict: PXRD谱字典 {sample_id: np.ndarray(11051,)}\n",
    "    \"\"\"\n",
    "    data_path = Path(data_path)\n",
    "    \n",
    "    # 加载组成信息\n",
    "    with open(data_path / 'composition.json', 'r') as f:\n",
    "        compositions_dict = json.load(f)\n",
    "    \n",
    "    # 加载PXRD谱\n",
    "    pxrd_dict = {}\n",
    "    pattern_dir = data_path / 'pattern'\n",
    "    \n",
    "    for sample_id in tqdm(compositions_dict.keys(), desc=\"加载PXRD谱\"):\n",
    "        pxrd_file = pattern_dir / f\"{sample_id}.xy\"\n",
    "        \n",
    "        # 读取xy文件，跳过第一行注释\n",
    "        data = np.loadtxt(pxrd_file, skiprows=1)\n",
    "        # 只取强度值（第二列）\n",
    "        pxrd_dict[sample_id] = data[:, 1].astype(np.float32)\n",
    "    \n",
    "    print(f\"加载了 {len(compositions_dict)} 个样本\")\n",
    "    print(f\"PXRD谱长度: {len(next(iter(pxrd_dict.values())))}\")\n",
    "    \n",
    "    return compositions_dict, pxrd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_composition(comp_str: str) -> Tuple[int, List[int]]:\n",
    "    \"\"\"\n",
    "    解析组成字符串为原子数量和类型\n",
    "    \n",
    "    Args:\n",
    "        comp_str: 如 \"Sr4 Be2 Re2 N8\"\n",
    "    \n",
    "    Returns:\n",
    "        num_atoms: 总原子数\n",
    "        atom_types: 原子序数列表\n",
    "    \"\"\"\n",
    "    comp = Composition(comp_str)\n",
    "    atom_list = []\n",
    "    \n",
    "    for element, count in comp.items():\n",
    "        atomic_num = Element(element).Z\n",
    "        atom_list.extend([atomic_num] * int(count))\n",
    "    \n",
    "    # 确保原子列表长度不超过52（根据CLAUDE.md的说明）\n",
    "    if len(atom_list) > 52:\n",
    "        raise ValueError(f\"原子数 {len(atom_list)} 超过最大限制52\")\n",
    "    \n",
    "    # padding到52维\n",
    "    padded_list = atom_list + [0] * (52 - len(atom_list))\n",
    "    \n",
    "    return len(atom_list), padded_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path: str):\n",
    "    \"\"\"\n",
    "    加载训练好的模型\n",
    "    \n",
    "    Args:\n",
    "        model_path: 模型checkpoint路径\n",
    "    \n",
    "    Returns:\n",
    "        model: 加载的模型\n",
    "    \"\"\"\n",
    "    # TODO: 这里需要根据实际的模型架构进行修改\n",
    "    # 目前只是占位符\n",
    "    \n",
    "    print(f\"加载模型: {model_path}\")\n",
    "    \n",
    "    # 示例代码，需要替换为实际的模型加载逻辑\n",
    "    # from src.trainer import LitModule\n",
    "    # model = LitModule.load_from_checkpoint(model_path)\n",
    "    # model.eval()\n",
    "    # model = model.to(device)\n",
    "    \n",
    "    return None  # 返回占位符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 批量推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(\n",
    "    sample_ids: List[str],\n",
    "    compositions_dict: Dict,\n",
    "    pxrd_dict: Dict[str, np.ndarray],\n",
    "    target_pxrd_dict: Optional[Dict[str, np.ndarray]] = None\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    准备一个批次的数据\n",
    "    \n",
    "    Args:\n",
    "        sample_ids: 批次中的样本ID列表\n",
    "        compositions_dict: 组成信息字典\n",
    "        pxrd_dict: PXRD谱字典\n",
    "        target_pxrd_dict: 目标PXRD谱字典（用于采样过程）\n",
    "    \n",
    "    Returns:\n",
    "        batch_data: 包含批次数据的字典\n",
    "    \"\"\"\n",
    "    batch_comps = []  # [batch_size, 52]\n",
    "    batch_pxrd = []   # [batch_size, 11051]\n",
    "    batch_target_pxrd = []  # [batch_size, 11051]\n",
    "    batch_num_atoms = []  # [batch_size]\n",
    "    \n",
    "    for sample_id in sample_ids:\n",
    "        # 获取组成（使用第一个，即niggli reduced cell）\n",
    "        comp_str = compositions_dict[sample_id][\"composition\"][0]\n",
    "        num_atoms, atom_types = parse_composition(comp_str)\n",
    "        \n",
    "        batch_comps.append(atom_types)\n",
    "        batch_num_atoms.append(num_atoms)\n",
    "        batch_pxrd.append(pxrd_dict[sample_id])\n",
    "        \n",
    "        # 如果有目标PXRD（用于采样中间过程）\n",
    "        if target_pxrd_dict:\n",
    "            batch_target_pxrd.append(target_pxrd_dict[sample_id])\n",
    "        else:\n",
    "            # 初始时使用相同的PXRD\n",
    "            batch_target_pxrd.append(pxrd_dict[sample_id])\n",
    "    \n",
    "    # 转换为tensor\n",
    "    batch_data = {\n",
    "        'comp': torch.tensor(batch_comps, dtype=torch.long, device=device),  # [batch_size, 52]\n",
    "        'pxrd': torch.tensor(np.stack(batch_pxrd), dtype=torch.float32, device=device),  # [batch_size, 11051]\n",
    "        'target_pxrd': torch.tensor(np.stack(batch_target_pxrd), dtype=torch.float32, device=device),  # [batch_size, 11051]\n",
    "        'num_atoms': torch.tensor(batch_num_atoms, dtype=torch.long, device=device),  # [batch_size]\n",
    "        'sample_ids': sample_ids\n",
    "    }\n",
    "    \n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_inference(\n",
    "    model,\n",
    "    batch_data: Dict[str, torch.Tensor],\n",
    "    num_sampling_steps: int = 100\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    批量推理生成晶体结构\n",
    "    \n",
    "    Args:\n",
    "        model: 训练好的模型\n",
    "        batch_data: 批次数据\n",
    "        num_sampling_steps: 采样步数\n",
    "    \n",
    "    Returns:\n",
    "        results: 包含生成结果的字典\n",
    "    \"\"\"\n",
    "    # TODO: 这里需要实现实际的推理逻辑\n",
    "    # 包括：\n",
    "    # 1. 初始化z（噪声）\n",
    "    # 2. 逐步采样（meanflow或cfm）\n",
    "    # 3. 在每步计算PXRD作为条件\n",
    "    # 4. 返回最终的晶体结构\n",
    "    \n",
    "    batch_size = batch_data['comp'].shape[0]\n",
    "    \n",
    "    # 示例输出（需要替换为实际推理）\n",
    "    # 模型输出: [batch_size, 3 + 52, 3]\n",
    "    # 前3个是晶格参数(3x3矩阵)，后52个是分数坐标\n",
    "    dummy_output = torch.randn(batch_size, 55, 3, device=device)\n",
    "    \n",
    "    # 解析输出\n",
    "    lattice_matrix = dummy_output[:, :3, :]  # [batch_size, 3, 3]\n",
    "    frac_coords = dummy_output[:, 3:, :]  # [batch_size, 52, 3]\n",
    "    \n",
    "    # 从晶格矩阵计算长度和角度\n",
    "    # 这里需要实际的转换逻辑\n",
    "    lengths = torch.rand(batch_size, 3, device=device) * 10 + 5  # 示例\n",
    "    angles = torch.rand(batch_size, 3, device=device) * 30 + 75  # 示例\n",
    "    \n",
    "    results = {\n",
    "        'lattice_matrix': lattice_matrix,\n",
    "        'frac_coords': frac_coords,\n",
    "        'lengths': lengths,\n",
    "        'angles': angles,\n",
    "        'num_atoms': batch_data['num_atoms'],\n",
    "        'comp': batch_data['comp'],\n",
    "        'sample_ids': batch_data['sample_ids']\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 后处理与优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_structure(results: Dict[str, torch.Tensor]) -> List[Structure]:\n",
    "    \"\"\"\n",
    "    后处理生成的结构\n",
    "    \n",
    "    Args:\n",
    "        results: 批量推理结果\n",
    "    \n",
    "    Returns:\n",
    "        structures: pymatgen Structure对象列表\n",
    "    \"\"\"\n",
    "    structures = []\n",
    "    batch_size = results['lengths'].shape[0]\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # 获取当前样本数据\n",
    "        num_atoms = results['num_atoms'][i].item()\n",
    "        comp = results['comp'][i].cpu().numpy()\n",
    "        frac_coords = results['frac_coords'][i][:num_atoms].cpu().numpy()  # 只取有效原子\n",
    "        lengths = results['lengths'][i].cpu().numpy()\n",
    "        angles = results['angles'][i].cpu().numpy()\n",
    "        \n",
    "        # 获取原子类型（去除padding）\n",
    "        atom_types = [z for z in comp[:num_atoms] if z > 0]\n",
    "        species = [Element.from_Z(z) for z in atom_types]\n",
    "        \n",
    "        # 创建晶格\n",
    "        lattice = Lattice.from_parameters(\n",
    "            lengths[0], lengths[1], lengths[2],\n",
    "            angles[0], angles[1], angles[2]\n",
    "        )\n",
    "        \n",
    "        # 创建结构\n",
    "        structure = Structure(lattice, species, frac_coords)\n",
    "        \n",
    "        # 可选：能量最小化或其他优化\n",
    "        # structure = optimize_structure(structure)\n",
    "        \n",
    "        structures.append(structure)\n",
    "    \n",
    "    return structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(\n",
    "    structures: List[Structure],\n",
    "    sample_ids: List[str],\n",
    "    output_path: str = \"submission.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    生成比赛提交文件\n",
    "    \n",
    "    Args:\n",
    "        structures: 生成的晶体结构列表\n",
    "        sample_ids: 样本ID列表\n",
    "        output_path: 输出文件路径\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for structure, sample_id in zip(structures, sample_ids):\n",
    "        # 转换为CIF格式\n",
    "        cif_str = structure.to(fmt=\"cif\")\n",
    "        rows.append([sample_id, cif_str])\n",
    "    \n",
    "    # 创建DataFrame并保存\n",
    "    df = pd.DataFrame(rows, columns=[\"ID\", \"cif\"])\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"提交文件已保存: {output_path}\")\n",
    "    print(f\"包含 {len(df)} 个结构\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 主流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "TEST_DATA_PATH = \"docs/data/test_v3/A\"  # 测试数据路径\n",
    "MODEL_PATH = \"outputs/model.ckpt\"  # 模型路径（需要修改为实际路径）\n",
    "BATCH_SIZE = 32  # 批处理大小\n",
    "NUM_SAMPLING_STEPS = 100  # 采样步数\n",
    "DRY_RUN = False  # 是否测试模式（只处理前10个样本）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    主函数：完整的推理流程\n",
    "    \"\"\"\n",
    "    # 1. 加载测试数据\n",
    "    print(\"=\"*50)\n",
    "    print(\"步骤1: 加载测试数据\")\n",
    "    compositions_dict, pxrd_dict = load_test_data(TEST_DATA_PATH)\n",
    "    \n",
    "    # 获取所有样本ID\n",
    "    sample_ids = list(compositions_dict.keys())\n",
    "    if DRY_RUN:\n",
    "        sample_ids = sample_ids[:10]\n",
    "        print(f\"DRY_RUN模式：只处理前{len(sample_ids)}个样本\")\n",
    "    \n",
    "    # 2. 加载模型\n",
    "    print(\"=\"*50)\n",
    "    print(\"步骤2: 加载模型\")\n",
    "    model = load_model(MODEL_PATH)\n",
    "    \n",
    "    # 3. 批量推理\n",
    "    print(\"=\"*50)\n",
    "    print(\"步骤3: 批量推理生成晶体结构\")\n",
    "    print(f\"批处理大小: {BATCH_SIZE}\")\n",
    "    print(f\"采样步数: {NUM_SAMPLING_STEPS}\")\n",
    "    \n",
    "    all_structures = []\n",
    "    all_sample_ids = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 分批处理\n",
    "    for i in tqdm(range(0, len(sample_ids), BATCH_SIZE), desc=\"批量推理\"):\n",
    "        batch_ids = sample_ids[i:i + BATCH_SIZE]\n",
    "        \n",
    "        # 准备批次数据\n",
    "        batch_data = prepare_batch(batch_ids, compositions_dict, pxrd_dict)\n",
    "        \n",
    "        # 批量推理\n",
    "        with torch.no_grad():\n",
    "            results = batch_inference(model, batch_data, NUM_SAMPLING_STEPS)\n",
    "        \n",
    "        # 后处理\n",
    "        structures = postprocess_structure(results)\n",
    "        \n",
    "        all_structures.extend(structures)\n",
    "        all_sample_ids.extend(batch_ids)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # 4. 生成提交文件\n",
    "    print(\"=\"*50)\n",
    "    print(\"步骤4: 生成提交文件\")\n",
    "    output_path = \"submission.csv\" if not DRY_RUN else \"submission_dryrun.csv\"\n",
    "    generate_submission(all_structures, all_sample_ids, output_path)\n",
    "    \n",
    "    # 打印统计信息\n",
    "    print(\"=\"*50)\n",
    "    print(\"推理完成！\")\n",
    "    print(f\"处理样本数: {len(all_structures)}\")\n",
    "    print(f\"总用时: {elapsed_time:.2f} 秒\")\n",
    "    print(f\"平均每个样本: {elapsed_time/len(all_structures):.3f} 秒\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行主流程\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 可视化与分析（可选）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pxrd(sample_id: str, pxrd_dict: Dict[str, np.ndarray]):\n",
    "    \"\"\"\n",
    "    可视化PXRD谱\n",
    "    \"\"\"\n",
    "    pxrd = pxrd_dict[sample_id]\n",
    "    theta = np.linspace(5, 115, len(pxrd))  # 2theta范围\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(theta, pxrd)\n",
    "    plt.xlabel('2θ (degrees)')\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.title(f'PXRD Pattern - {sample_id}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(structures: List[Structure]):\n",
    "    \"\"\"\n",
    "    分析生成的晶体结构\n",
    "    \"\"\"\n",
    "    # 统计晶格参数分布\n",
    "    lengths_a = [s.lattice.a for s in structures]\n",
    "    lengths_b = [s.lattice.b for s in structures]\n",
    "    lengths_c = [s.lattice.c for s in structures]\n",
    "    \n",
    "    angles_alpha = [s.lattice.alpha for s in structures]\n",
    "    angles_beta = [s.lattice.beta for s in structures]\n",
    "    angles_gamma = [s.lattice.gamma for s in structures]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    \n",
    "    # 晶格长度分布\n",
    "    axes[0, 0].hist(lengths_a, bins=30, alpha=0.7)\n",
    "    axes[0, 0].set_title('Lattice a')\n",
    "    axes[0, 0].set_xlabel('Length (Å)')\n",
    "    \n",
    "    axes[0, 1].hist(lengths_b, bins=30, alpha=0.7)\n",
    "    axes[0, 1].set_title('Lattice b')\n",
    "    axes[0, 1].set_xlabel('Length (Å)')\n",
    "    \n",
    "    axes[0, 2].hist(lengths_c, bins=30, alpha=0.7)\n",
    "    axes[0, 2].set_title('Lattice c')\n",
    "    axes[0, 2].set_xlabel('Length (Å)')\n",
    "    \n",
    "    # 晶格角度分布\n",
    "    axes[1, 0].hist(angles_alpha, bins=30, alpha=0.7)\n",
    "    axes[1, 0].set_title('Angle α')\n",
    "    axes[1, 0].set_xlabel('Angle (degrees)')\n",
    "    \n",
    "    axes[1, 1].hist(angles_beta, bins=30, alpha=0.7)\n",
    "    axes[1, 1].set_title('Angle β')\n",
    "    axes[1, 1].set_xlabel('Angle (degrees)')\n",
    "    \n",
    "    axes[1, 2].hist(angles_gamma, bins=30, alpha=0.7)\n",
    "    axes[1, 2].set_title('Angle γ')\n",
    "    axes[1, 2].set_xlabel('Angle (degrees)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 打印统计信息\n",
    "    print(\"晶格参数统计:\")\n",
    "    print(f\"a: {np.mean(lengths_a):.2f} ± {np.std(lengths_a):.2f} Å\")\n",
    "    print(f\"b: {np.mean(lengths_b):.2f} ± {np.std(lengths_b):.2f} Å\")\n",
    "    print(f\"c: {np.mean(lengths_c):.2f} ± {np.std(lengths_c):.2f} Å\")\n",
    "    print(f\"α: {np.mean(angles_alpha):.2f} ± {np.std(angles_alpha):.2f}°\")\n",
    "    print(f\"β: {np.mean(angles_beta):.2f} ± {np.std(angles_beta):.2f}°\")\n",
    "    print(f\"γ: {np.mean(angles_gamma):.2f} ± {np.std(angles_gamma):.2f}°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: 与实际模型集成\n",
    "\n",
    "当前notebook提供了完整的推理框架，但需要与实际训练的模型集成：\n",
    "\n",
    "1. **模型加载**：需要导入实际的模型类（如从`src.trainer`或`src.networks`）\n",
    "2. **推理逻辑**：实现`batch_inference`函数中的实际推理流程，包括：\n",
    "   - meanflow或cfm的采样过程\n",
    "   - 实时PXRD计算与条件注入\n",
    "   - 正确的输出解析\n",
    "3. **PXRD计算**：集成`src.PXRDSimulator`用于采样过程中的PXRD计算\n",
    "4. **后处理优化**：可选添加能量最小化等优化步骤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
